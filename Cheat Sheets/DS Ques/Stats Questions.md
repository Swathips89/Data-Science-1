1. Why would one use the t-distribution over the normal?
2. What are the strongest assumptions of OLS?
3. Why do we care about power in experiments?
4. What do frequentists and Bayesians disagree about?
5. When would you use a self join?
6. How can you use a join as a filter condition?
7. What does it mean for R and Python to be vectorized?
8. Why would you use a dictionary vs. a list? Examples?
9. How does the amount of variance affect power?
10. What does it mean to overfit a tree based model?

1. T-tests. Know their assumptions. Know how the t distribution relates to the normal distribution.
2. Central Limit Theorem. Know what it means for the distribution of the mean. Understand the magic!
3. Regression assumptions. Know why independence of observations matters and what IID means.
4. Confidence intervals and relationship to hypothesis tests. Discuss relationship to credible intervals.
5. The implications of Bayesian priors vs frequentist perspective. What does it mean for practical decision making?

1. Know what a p-value is and its limitations in decisions.
2. Linear regression and its assumptions.
3. When to use different statistical distributions.
4. How an effect size impacts results/decisions.
5. Mean, variance for Normal, Uniform, Poisson.
6. Sampling techniques and common designs (e.g. A/B).
7. Bayes' theorem (applied calculations).
8. Confidence intervals measurement and interpretation.
9. Logistic regression and ROC curves.
10. Resampling (Cross validation + bootstrapping).
11. Dimensionality reduction.
12. Tree-based models (particularly how to prune).
13. Ridge and Lasso for regression.
