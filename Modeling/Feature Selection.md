### Links
Genetic Algorithm https://www.analyticsvidhya.com/blog/2017/07/introduction-to-genetic-algorithm/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29 <br/>
https://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html <br/>
Dimension reduction techniques https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/


### Reasons to include fewer predictors over many
* Redundancy/Irrelevance: Remove non-redundant predictor variables
* Over-fitting: he data models with large number of predictors (also referred to as complex models) often suffer from the problem of overfitting, in which case the data model performs great on training data, but performs poorly on test data.
* Productivity: 
* Understandability:

### Feature reduction techniques:
* Dimensionality reduction: 
  * Principal Component Analysis (PCA)
  * Multiple Correspondence Analysis (MCA) - Categorical variables
  * CorEx - Recent technique for automatic structure extraction from categorical data - https://github.com/gregversteeg/CorEx
  * Self-organizing maps (SOM)
  * Latent Semantic Indexing
* Manifold Learning: t-Distributed Stochastic Neighbor Embedding (t-SNE)
* Variational autoencoders: An automated generative approach using variational autoencoders (VAE)
* Clustering: Hierarchical Clustering
* Forward slection, Backward Selection, Stepwise Selection
* Regularization - Lasso Regression
* Remove correlated variables 
* Measure information gain for the available set of features and select top n features accordingly
* Use regression and select variables based on p values






