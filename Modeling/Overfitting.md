### Links
https://www.kdnuggets.com/2015/08/feldman-avoid-overfitting-holdout-adaptive-data-analysis.html
https://arxiv.org/pdf/1506.02629.pdf
https://www.oreilly.com/ideas/3-ideas-to-add-to-your-data-science-toolkit
https://ai.googleblog.com/2015/08/the-reusable-holdout-preserving.html

### Problem
* Though we use a holdset to verify our model built on training set, we use holdset to revise parameters or algorithm, this frequantly leads to over-fitting on holdout set

### Solution
* Regularization
* 


### Thresholdout - Reusable holdout sets
* The limit of the method is determined by the size of the holdout set - the number of times that the holdout set may be used grows roughly as the square of the number of collected data points in the holdout, as our theory shows.
* Based on Differential privacy - It is a notion of stability requiring that any single sample should not influence the outcome of the analysis significantly.





